{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062528,
     "end_time": "2020-01-31T17:15:03.390105",
     "exception": false,
     "start_time": "2020-01-31T17:15:03.327577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "julie.tsitron@parks.nyc.gov 1/8/2020\n",
    "\n",
    "This notebook is for testing various ArcGIS API for Python functions that allow for pushing/updating GIS data to production servers. Ultimately, the script from this notebook can be used as a template for the technical implementation (i.e., pushing clean data into production ESRI-based geodatabases) of Structures, Sites and Units, CPAs, and other Agency Data Model data products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078129,
     "end_time": "2020-01-31T17:15:03.546321",
     "exception": false,
     "start_time": "2020-01-31T17:15:03.468192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports and Connections to DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 2.859371,
     "end_time": "2020-01-31T17:15:09.436953",
     "exception": false,
     "start_time": "2020-01-31T17:15:06.577582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from urllib.parse import quote\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import sys\n",
    "sys.path.append('../') ## <-- THIS IS THE PART THAT TELLS IT TO LOOK IN THE PARENT DIRECTORY\n",
    "from IPM_Shared_Code.Python.geo_functions import read_geosql\n",
    "from IPM_Shared_Code.Python.email_functions import get_contacts, read_template, send_email\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor, SpatialDataFrame, FeatureLayer\n",
    "import json\n",
    "from datetime import datetime\n",
    "import arcgis\n",
    "import utils\n",
    "import urllib\n",
    "import sqlalchemy\n",
    "import os\n",
    "import shapely\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093739,
     "end_time": "2020-01-31T17:15:09.608807",
     "exception": false,
     "start_time": "2020-01-31T17:15:09.515068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = utils.get_config('config.ini')\n",
    "\n",
    "driver = config['srv']['driver']\n",
    "vpipm_server = config['srv']['vpipm']\n",
    "parksgis_dev_server = config['srv']['parksgis_dev']\n",
    "parksgis_prod_server = config['srv']['parksgis_prod']\n",
    "data_parks_server = config['srv']['data_parks']\n",
    "\n",
    "structuresdb = config['db']['structuresdb']\n",
    "\n",
    "geo_key = config['keys']['geosupport_key']\n",
    "geo_ip = config['keys']['geosupport_ip']\n",
    "\n",
    "portal_dev = config['url']['portal_dev']\n",
    "portal_prod = config['url']['portal_prod']\n",
    "structures_dev_url = config['url']['structures_dev']\n",
    "structures_prod_url = config['url']['structures_prod']\n",
    "geosupport_dev_url = config['url']['geosupport_dev']\n",
    "geosupport_prod_url = config['url']['geosupport_prod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.265578,
     "end_time": "2020-01-31T17:15:09.952585",
     "exception": false,
     "start_time": "2020-01-31T17:15:09.687007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "con_vpipm = pyodbc.connect('Driver={' + driver + '};Server=' + vpipm_server +\n",
    "                           ';Database=' + structuresdb +\n",
    "                           ';Trusted_Connection=Yes;')\n",
    "con_gis_dev = pyodbc.connect('Driver={SQL Server};Server=' +\n",
    "                             parksgis_dev_server +\n",
    "                             ';Database=;Trusted_Connection=Yes;') \n",
    "con_gis_prod = pyodbc.connect('Driver={SQL Server};Server=' +\n",
    "                             parksgis_prod_server +\n",
    "                             ';Database=;Trusted_Connection=Yes;') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.249983,
     "end_time": "2020-01-31T17:15:10.280709",
     "exception": false,
     "start_time": "2020-01-31T17:15:10.030726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "crsr = con_vpipm.cursor()\n",
    "crsr.execute(\"{CALL structuresdb.dbo.sp_i_tbl_overlap_exceptions}\")\n",
    "crsr.commit()\n",
    "crsr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsr = con_vpipm.cursor()\n",
    "crsr.execute(\"{CALL structuresdb.dbo.sp_i_tbl_audit_structures}\")\n",
    "crsr.commit()\n",
    "crsr.close()\n",
    "# con_vpipm.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsr = con_vpipm.cursor()\n",
    "sql_stmt = '''\n",
    "exec [structuresdb].[dbo].[sp_i_tbl_delta_structures_archive] \n",
    "'''\n",
    "crsr.execute(\"{CALL [structuresdb].[dbo].[sp_i_tbl_delta_structures_archive] }\")\n",
    "crsr.commit()\n",
    "crsr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.156241,
     "end_time": "2020-01-31T17:15:10.546343",
     "exception": false,
     "start_time": "2020-01-31T17:15:10.390102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = urllib.parse.quote_plus(r'Driver=' + driver + ';Server=' +\n",
    "                                 vpipm_server + ';Database=' + structuresdb +\n",
    "                                 ';Trusted_Connection=Yes;')\n",
    "engine = sqlalchemy.create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078132,
     "end_time": "2020-01-31T17:15:11.577570",
     "exception": false,
     "start_time": "2020-01-31T17:15:11.499438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078147,
     "end_time": "2020-01-31T17:15:11.733860",
     "exception": false,
     "start_time": "2020-01-31T17:15:11.655713",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deal with Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078153,
     "end_time": "2020-01-31T17:15:11.905741",
     "exception": false,
     "start_time": "2020-01-31T17:15:11.827588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## m/d/Y H:M:S format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.124985,
     "end_time": "2020-01-31T17:15:12.124467",
     "exception": false,
     "start_time": "2020-01-31T17:15:11.999482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structures_dev['COMMISSIONDATE'] = pd.to_datetime(\n",
    "#     structures_dev['COMMISSIONDATE'],\n",
    "#     errors='coerce').dt.strftime('%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.109417,
     "end_time": "2020-01-31T17:15:12.327659",
     "exception": false,
     "start_time": "2020-01-31T17:15:12.218242",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structures_dev['COMMISSIONDATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.140601,
     "end_time": "2020-01-31T17:15:12.530702",
     "exception": false,
     "start_time": "2020-01-31T17:15:12.390101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structures_dev['FEATURESTATUSCHANGEDATE'] = pd.to_datetime(\n",
    "#     structures_dev['FEATURESTATUSCHANGEDATE']).dt.strftime('%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.109353,
     "end_time": "2020-01-31T17:15:12.749463",
     "exception": false,
     "start_time": "2020-01-31T17:15:12.640110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structures_dev['RETIREDDATE'] = pd.to_datetime(\n",
    "#     structures_dev['RETIREDDATE']).dt.strftime('%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093721,
     "end_time": "2020-01-31T17:15:12.921333",
     "exception": false,
     "start_time": "2020-01-31T17:15:12.827612",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structures_dev.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062521,
     "end_time": "2020-01-31T17:15:13.046363",
     "exception": false,
     "start_time": "2020-01-31T17:15:12.983842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Delta Table from structuresdb (on vpipm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_structures = '''\n",
    "select * from [ParksGIS].[DPR].[STRUCTURE_EVW] \n",
    "'''\n",
    "structures_latest = read_geosql(sql_structures,\n",
    "                            con_gis_dev,\n",
    "                            geom_raw='SHAPE',\n",
    "                            geom_col='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tz_aware_UTC(row, column):\n",
    "    return pd.to_datetime(row[column]).tz_localize('UTC').astimezone(pytz.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tz_aware_EST(row, column):\n",
    "    return pd.to_datetime(row[column]).tz_localize('EST').astimezone(pytz.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_latest['last_edited_date'] = structures_latest.apply(lambda row: make_tz_aware_UTC(row, 'last_edited_date'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.31251,
     "end_time": "2020-01-31T17:15:13.436978",
     "exception": false,
     "start_time": "2020-01-31T17:15:13.124468",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SPATIAL DATASET:\n",
    "con_vpipm = pyodbc.connect('Driver={' + driver + '};Server=' + vpipm_server +\n",
    "                           ';Database=' + structuresdb +\n",
    "                           ';Trusted_Connection=Yes;')\n",
    "sql_str_deltas = '''\n",
    "select * FROM [structuresdb].[dbo].[tbl_delta_structures] \n",
    "'''\n",
    "\n",
    "struct_deltas = read_geosql(sql_str_deltas,\n",
    "                            con_vpipm,\n",
    "                            geom_raw='shape',\n",
    "                            geom_col='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.078108,
     "end_time": "2020-01-31T17:15:13.577581",
     "exception": false,
     "start_time": "2020-01-31T17:15:13.499473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Still need this ??\n",
    "\n",
    "struct_deltas.rename(columns={\n",
    "    'objectid': 'OBJECTID',\n",
    "    'parks_id': 'SYSTEM',\n",
    "    'bin': 'BIN',\n",
    "    'bbl': 'BBL',\n",
    "    'doitt_id': 'DOITT_ID',\n",
    "    'ground_elevation': 'Ground_Elevation',\n",
    "    'height_roof': 'Height_Roof',\n",
    "    'alteration_year': 'Alteration_Year',\n",
    "    'construction_year': 'Construction_Year',\n",
    "    'demolition_year': 'Demolition_Year'\n",
    "},\n",
    "                     inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "struct_deltas['date_stamp'] =struct_deltas.apply(lambda row: make_tz_aware_UTC(row, 'date_stamp'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_push_api = structures_latest[\n",
    "    (structures_latest['last_edited_user'] == 'NYCDPR\\py_services')\n",
    "    & (structures_latest['last_edited_date'] ==\n",
    "       structures_latest['last_edited_date'].max())]['last_edited_date'].loc[0]\n",
    "last_push_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_deltas[struct_deltas['date_stamp']>last_push_api]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_deltas = struct_deltas[struct_deltas['date_stamp']>last_push_api]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.140668,
     "end_time": "2020-01-31T17:15:13.780765",
     "exception": false,
     "start_time": "2020-01-31T17:15:13.640097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "struct_deltas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093739,
     "end_time": "2020-01-31T17:15:13.936955",
     "exception": false,
     "start_time": "2020-01-31T17:15:13.843216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def to_wkt(row):\n",
    "#     return row.wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.125016,
     "end_time": "2020-01-31T17:15:14.733865",
     "exception": false,
     "start_time": "2020-01-31T17:15:14.608849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Write Delta Table to geojson file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.687505,
     "end_time": "2020-01-31T17:15:16.499477",
     "exception": false,
     "start_time": "2020-01-31T17:15:14.811972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not struct_deltas.empty:\n",
    "    today = datetime.now().strftime('%Y%m%d')\n",
    "    snapshot = r'C:\\\\Projects\\\\AgencyDataModel\\\\Develop\\\\Structures\\\\delta_snapshots/' + today\n",
    "    if os.path.exists(snapshot):\n",
    "        struct_deltas.to_file(snapshot + '/deltas.geojson',\n",
    "                              encoding='utf-8',\n",
    "                              driver='GeoJSON')\n",
    "    else:\n",
    "        os.makedirs(snapshot)\n",
    "        struct_deltas.to_file(snapshot + '/deltas.geojson',\n",
    "                              encoding='utf-8',\n",
    "                              driver='GeoJSON')\n",
    "\n",
    "    # Read geojson file to geojson object \n",
    "\n",
    "    with open(snapshot+'/deltas.geojson') as data:\n",
    "        geojson_deltas = json.load(data)\n",
    "\n",
    "    # Create arcgis featureSet from geojson object\n",
    "\n",
    "    fromJSON_deltas = arcgis.features.FeatureSet.from_geojson(geojson_deltas)\n",
    "\n",
    "    # Connect to published dataset via GIS object\n",
    "\n",
    "    gis = GIS(url=portal_dev)\n",
    "\n",
    "    # Connect to feature layer directly\n",
    "\n",
    "    strct_lyr_url = structures_dev_url\n",
    "\n",
    "    lyr_structures = FeatureLayer(strct_lyr_url)\n",
    "    structures_features = lyr_structures.query()\n",
    "\n",
    "    structures_features\n",
    "\n",
    "    len(struct_deltas)\n",
    "\n",
    "    # Make Edits\n",
    "\n",
    "    update_result = lyr_structures.edit_features(updates=fromJSON_deltas.features)\n",
    "\n",
    "    lyr_structures = FeatureLayer(strct_lyr_url)\n",
    "    structures_features = lyr_structures.query()\n",
    "else:\n",
    "    # Connect to published dataset via GIS object\n",
    "    gis = GIS(url=portal_dev)\n",
    "\n",
    "    # Connect to feature layer directly\n",
    "\n",
    "    strct_lyr_url = structures_dev_url\n",
    "\n",
    "    lyr_structures = FeatureLayer(strct_lyr_url)\n",
    "    structures_features = lyr_structures.query()\n",
    "\n",
    "    structures_features\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078144,
     "end_time": "2020-01-31T17:17:38.421734",
     "exception": false,
     "start_time": "2020-01-31T17:17:38.343590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Connect to feature service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.656264,
     "end_time": "2020-01-31T17:17:39.156061",
     "exception": false,
     "start_time": "2020-01-31T17:17:38.499797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gis = GIS(url=portal_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062502,
     "end_time": "2020-01-31T17:17:39.296672",
     "exception": false,
     "start_time": "2020-01-31T17:17:39.234170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## geosupport table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.109374,
     "end_time": "2020-01-31T17:17:39.484172",
     "exception": false,
     "start_time": "2020-01-31T17:17:39.374798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "geosupport_tbl_url = geosupport_dev_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.531183,
     "end_time": "2020-01-31T17:17:40.093558",
     "exception": false,
     "start_time": "2020-01-31T17:17:39.562375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tbl_geosupport = FeatureLayer(geosupport_tbl_url)\n",
    "geosupport = tbl_geosupport.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078067,
     "end_time": "2020-01-31T17:17:40.249821",
     "exception": false,
     "start_time": "2020-01-31T17:17:40.171754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get latest BINs from structures layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.812485,
     "end_time": "2020-01-31T17:17:41.124824",
     "exception": false,
     "start_time": "2020-01-31T17:17:40.312339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "structures_valid_BINs = structures_features.sdf[\n",
    "    (structures_features.sdf['BIN'] != 0) &\n",
    "    (~pd.isnull(structures_features.sdf['BIN']))]  #['BIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.124986,
     "end_time": "2020-01-31T17:17:41.327938",
     "exception": false,
     "start_time": "2020-01-31T17:17:41.202952",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins = structures_valid_BINs[structures_valid_BINs['BIN'].astype(int)%100000!=0]['BIN'].astype(int).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093711,
     "end_time": "2020-01-31T17:17:41.640418",
     "exception": false,
     "start_time": "2020-01-31T17:17:41.546707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bins = [str(bins[i]) for i in range(0, len(bins))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093723,
     "end_time": "2020-01-31T17:17:41.812294",
     "exception": false,
     "start_time": "2020-01-31T17:17:41.718571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = geo_key\n",
    "grc_err = ['01/F', '20', '21', '22', '23']\n",
    "out_keys = [\n",
    "    'AddressRangeList', 'out_bbl', 'out_TPAD_bin', 'out_TPAD_bin_status',\n",
    "    'out_TPAD_conflict_flag', 'out_error_message', 'out_grc',\n",
    "    'out_sanborn_boro', 'in_bin', 'out_bbl_boro'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093732,
     "end_time": "2020-01-31T17:17:41.984173",
     "exception": false,
     "start_time": "2020-01-31T17:17:41.890441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def funcbn(bn=None, out_keys=None, grc_err=None,api_key=None,ip=None):\n",
    "    \n",
    "    url = 'http://{}/geoservice/geoservice.svc/Function_BIN?BIN={}&key={}'.format(ip, bn, api_key)\n",
    "    #Encode the url, but allow the characters specified in the safe argument.\n",
    "    url = quote(url, safe = ':/?&=')\n",
    "    \n",
    "    geo_dict = {}\n",
    "    obj_to_return = {}\n",
    "    #Establish the connection\n",
    "    http = urllib3.PoolManager()\n",
    "    try:\n",
    "        #Send the get request to the AWS API and retrieve the response\n",
    "        response = http.request('GET', url)\n",
    "        #Load the JSON that is returned keeping only the values in the display key\n",
    "        raw_dict = json.loads(response.data).get('display')\n",
    "        \n",
    "        #Keep only the dictionary keys the function caller wants to retain\n",
    "        geo_dict = {k: raw_dict[k] for k in out_keys}                \n",
    "        \n",
    "        if geo_dict['out_grc'].strip() in grc_err:\n",
    "            #bin_dict.update(geo_dict)\n",
    "            obj_to_return['bin'] = bn\n",
    "            del geo_dict['AddressRangeList']\n",
    "            obj_to_return.update(geo_dict)\n",
    "        else:\n",
    "            geo_dict2 = geo_dict.copy()\n",
    "            del geo_dict2['AddressRangeList']\n",
    "            for i in geo_dict['AddressRangeList']:\n",
    "                i.update(geo_dict2)\n",
    "            obj_to_return = geo_dict['AddressRangeList']\n",
    "        \n",
    "    except:       \n",
    "        print('exception!')\n",
    "        #Set the output equal to the input BIN so that no information is lost\n",
    "        add_dict = [bin_dict]\n",
    "    # returns either list or dict:\n",
    "    return obj_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.124912,
     "end_time": "2020-01-31T17:17:42.187299",
     "exception": false,
     "start_time": "2020-01-31T17:17:42.062387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def func1b(borough=None, addressno=None, streetname=None, api_key=None, ip=None):\n",
    "    url = ('http://{}/geoservice/geoservice.svc/Function_1B?Borough={}&AddressNo={}&StreetName={}&key={}'.\n",
    "           format(ip, borough, addressno, streetname, api_key))\n",
    "    #Encode the url, but allow the characters specified in the safe argument.\n",
    "    url = quote(url, safe = ':/?&=')\n",
    "    \n",
    "    #print('Checking Addresses: {} {} {}'.format(borough, addressno, streetname))\n",
    "    #Feed in the url with the BIN and the API Key and read the results\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', url)\n",
    "\n",
    "    #If any of these Return Codes are output then send the (includes all return codes for functions 1, 1A, 1B and 1E)\n",
    "    #REFERENCE: https://nycplanning.github.io/Geosupport-UPG/appendices/appendix01/#function-1\n",
    "    out_grc = ['01/E', '01/V', '01/P', '01/8', '01/A', '??/1', \n",
    "               '04', '07', '28', '29' '41', '42', '50', '56', \n",
    "               '69/B', '73', '75', '89', '90']\n",
    "\n",
    "    #Create a tuple of the keys that need to be retained\n",
    "    out_keys = ('out_zip_code', 'out_hurricane_zone', 'out_co', 'out_cd', \n",
    "                'out_sd','out_nta', 'out_ad', 'out_com_dist', 'out_fire_bat', \n",
    "                'out_fire_co', 'out_fire_co_str', 'out_fire_div', 'out_b10sc1',\n",
    "                'out_police_patrol_boro', 'out_police_area', 'out_police_pct', \n",
    "                'out_san_sched', 'out_san_dist_section', 'out_san_recycle', 'out_san_reg', 'out_san_org_pick_up',\n",
    "                'out_usps_city_name', 'out_preferred_lgc', 'out_sos_ind', 'out_physical_id')\n",
    "\n",
    "    #Load the dictionary nested in the display dictionary\n",
    "    raw_dict = json.loads(response.data).get('display')\n",
    "\n",
    "    #Only keep the keys that are needed\n",
    "    geo_dict = {k: raw_dict[k] for k in out_keys}\n",
    "\n",
    "    return geo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093741,
     "end_time": "2020-01-31T17:17:42.343544",
     "exception": false,
     "start_time": "2020-01-31T17:17:42.249803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flat_list(in_list=None):\n",
    "    \n",
    "    #This function will take the return from Geosupport Function BN aka BIN and make the return all of the same type.\n",
    "    #The raw return could produce a mixed list that contains a list of length 1 with 1 dictionary, a list of length \n",
    "    #1+n with 1+n dictionaries or simply a dictionary (if a GRC code is encountered).\n",
    "    \n",
    "    #Initialize the new list\n",
    "    new_list = []\n",
    "    \n",
    "    #Iterate through the input list elements\n",
    "    for i in in_list:\n",
    "        #If the element is a list instance/type then check the length.\n",
    "        if isinstance(i, list):\n",
    "            #If the list contains more than one element (length > 1) then extract each element and append as a\n",
    "            #type list element to the new list.\n",
    "            if len(i) > 1:\n",
    "                for j in i:\n",
    "                    new_list.append([j])\n",
    "            else:\n",
    "            #Otherwise append the single type list element to the new list.\n",
    "                new_list.append(i)\n",
    "        #If the element is not a list instance/type (it will be a dict) then append as a type list element to the new\n",
    "        #list.\n",
    "        else:\n",
    "            new_list.append([i])\n",
    "    #new_list is now a list of lists with each inner list containing a single dictionary.\n",
    "    \n",
    "    #Flatten the list of list so that the return is a list of dictionaries and the inner list is removed.\n",
    "    #Extract all inner list elements (dictionaries) from the outer list element.\n",
    "    return_list = [inner_el for outer_el in new_list for inner_el in outer_el]\n",
    "    \n",
    "    #Return the flattened list.\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093747,
     "end_time": "2020-01-31T17:17:42.499797",
     "exception": false,
     "start_time": "2020-01-31T17:17:42.406050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define a function that strips the leading and trailing spaces from the returned values of the dictionaries\n",
    "def strip_vals(in_list):\n",
    "    for dicts in in_list:\n",
    "        dicts.update((k, v.strip()) for k, v in dicts.items() if isinstance(v, str) )\n",
    "        #return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093733,
     "end_time": "2020-01-31T17:17:42.671671",
     "exception": false,
     "start_time": "2020-01-31T17:17:42.577938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_na(in_list):\n",
    "    for dicts in in_list:\n",
    "        dicts.update((k, None) for k, v in dicts.items() if v == 'N/A' or (isinstance(v, str) and v == ''))\n",
    "        #return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093752,
     "end_time": "2020-01-31T17:17:42.843548",
     "exception": false,
     "start_time": "2020-01-31T17:17:42.749796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_ck(in_list):\n",
    "    for dicts in in_list:\n",
    "        if dicts['out_grc'].strip('00') == '':\n",
    "            \n",
    "            #Check for equality and validity of low and high house number. The low and high house numbers need cannot be blank and\n",
    "            #must be equal to use as input into function 1.\n",
    "            if (dicts['high_address_number'].strip() == dicts['low_address_number'].strip() and \n",
    "               (dicts['high_address_number'].strip() != '' and dicts['low_address_number'].strip() != '')):          \n",
    "                add_val = {'addressable': 'Addressable'}\n",
    "                \n",
    "            #If the low and high range are not equal then the record should not be input into function 1.\n",
    "            else:\n",
    "                add_val = {'addressable': 'Non-Addressable, Range'}\n",
    "                \n",
    "        \n",
    "        else:\n",
    "            add_val = {'addressable':'Non-Addressable: {}'.format(dicts['out_error_message'].strip())}\n",
    "            \n",
    "        dicts.update(add_val)\n",
    "    #return dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078118,
     "end_time": "2020-01-31T17:17:43.124839",
     "exception": false,
     "start_time": "2020-01-31T17:17:43.046721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Call the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.09373,
     "end_time": "2020-01-31T17:17:43.281055",
     "exception": false,
     "start_time": "2020-01-31T17:17:43.187325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def master_func(in_bins):\n",
    "    list_of_things = []\n",
    "\n",
    "    for bn in in_bins:\n",
    "        list_of_things.append(funcbn(bn, out_keys = out_keys, grc_err = grc_err, api_key = geo_key, ip = geo_ip))\n",
    "    \n",
    "    t = flat_list(list_of_things)\n",
    "    \n",
    "    strip_vals(t)\n",
    "    add_ck(t)\n",
    "    \n",
    "    for dicts in t:\n",
    "        if dicts['addressable'] == 'Addressable':\n",
    "            new_dict = func1b(dicts['out_sanborn_boro'], dicts['high_address_number'], dicts['street_name'], geo_key, geo_ip)\n",
    "            dicts.update(new_dict)\n",
    "    \n",
    "    strip_vals(t)        \n",
    "    replace_na(t)\n",
    "    \n",
    "    return_df = pd.DataFrame(t)\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 134.094048,
     "end_time": "2020-01-31T17:19:57.437630",
     "exception": false,
     "start_time": "2020-01-31T17:17:43.343582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = master_func(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.171861,
     "end_time": "2020-01-31T17:19:57.672003",
     "exception": false,
     "start_time": "2020-01-31T17:19:57.500142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Rename all of the columns from Geosupport so that they map exactly to the schema in SQL Server\n",
    "dff = (df.rename(columns = {'out_zip_code': 'Zip_Code',\n",
    "                               'b7sc': 'B7SC',\n",
    "                               'out_b10sc1': 'B10SC',\n",
    "                               'out_sanborn_boro': 'Boro_Code',\n",
    "                               'bin': 'BIN',\n",
    "                               'out_preferred_lgc': 'LGC',\n",
    "                               'type_meaning': 'Address_Type',\n",
    "                               'high_address_number': 'High_House_Num',\n",
    "                               'low_address_number': 'Low_House_Num',\n",
    "                               'out_sos_ind': 'Street_Side',\n",
    "                               'street_name': 'Norm_Street_Name',\n",
    "                               'out_usps_city_name': 'USPS_City',\n",
    "                               'out_TPAD_bin_status': 'TPAD_BIN_Status',\n",
    "                               'out_co': 'City_Council',\n",
    "                               'out_ad': 'NYS_Assembly',\n",
    "                               'out_sd': 'NYS_Senate',\n",
    "                               'out_cd': 'US_Congress',\n",
    "                               'out_nta': 'NTA_Code',\n",
    "                               'out_fire_bat': 'Fire_Battalion',\n",
    "                               'out_fire_co': 'Fire_Co_Num',\n",
    "                               'out_fire_co_str': 'Fire_Co_Type',\n",
    "                               'out_fire_div': 'Fire_Division',\n",
    "                               'out_hurricane_zone': 'HEZ',\n",
    "                               'out_police_patrol_boro': 'Police_Boro',\n",
    "                               'Police Patrol Borough Command': 'Police_Boro_Com',\n",
    "                               'out_police_pct': 'Police_Precinct',\n",
    "                               'Sanitation Collection Scheduling Section and Subsection': 'Sanitation_Subsect',\n",
    "                               'Sanitation District': 'Sanitation_District',\n",
    "                               'Sanitation Recycling Collection Schedule': 'Sanitation_Recycling',\n",
    "                               'out_san_reg': 'Sanitation_Reg_Pickup',\n",
    "                               'out_physical_id': 'Physical_ID'})\n",
    "       .reindex(columns = ['BIN', 'Boro_Code', 'Address_Type', 'Low_House_Num', 'High_House_Num', 'Norm_Street_Name', 'USPS_City', \n",
    "                           'Zip_Code', 'Physical_ID', 'B7SC', 'B10SC', 'LGC', 'Street_Side', 'TPAD_BIN_Status', 'HEZ', \n",
    "                           'Community_Board', 'City_Council', 'NYS_Assembly', 'NYS_Senate', 'US_Congress', 'NTA_Code', \n",
    "                           'Fire_Battalion', 'Fire_Co_Num', 'Fire_Co_Type', 'Fire_Division', \n",
    "                           'Police_Boro', 'Police_Boro_Com', 'Police_Precinct', \n",
    "                           'Sanitation_Subsect', 'Sanitation_District', 'Sanitation_Recycling', 'Sanitation_Reg_Pickup'])\n",
    "       .drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093758,
     "end_time": "2020-01-31T17:19:57.828244",
     "exception": false,
     "start_time": "2020-01-31T17:19:57.734486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "measurer = np.vectorize(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.281247,
     "end_time": "2020-01-31T17:19:58.172000",
     "exception": false,
     "start_time": "2020-01-31T17:19:57.890753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "type_df = pd.DataFrame({'df_name': dff.columns.tolist(),\n",
    "                        'df_type': dff.dtypes.astype(str).tolist(),\n",
    "                        'df_len' : measurer(dff.values.astype(str)).max(axis=0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093726,
     "end_time": "2020-01-31T17:19:58.328238",
     "exception": false,
     "start_time": "2020-01-31T17:19:58.234512",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "type_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.15625,
     "end_time": "2020-01-31T17:19:58.547007",
     "exception": false,
     "start_time": "2020-01-31T17:19:58.390757",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.093741,
     "end_time": "2020-01-31T17:19:58.703241",
     "exception": false,
     "start_time": "2020-01-31T17:19:58.609500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "con_str = \"Driver={SQL Server};Server=\" + vpipm_server + \";Database=structuresdb;Trusted_Connection=Yes;\"\n",
    "sa_con = quote_plus(con_str)\n",
    "engine = sqlalchemy.create_engine(\n",
    "    \"mssql+pyodbc:///?odbc_connect={}\".format(sa_con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.593809,
     "end_time": "2020-01-31T17:20:04.359559",
     "exception": false,
     "start_time": "2020-01-31T17:19:58.765750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(dff) > 0:\n",
    "    dff.to_sql('tbl_geosupport_address', engine, schema = 'dbo', if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff.fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.281223,
     "end_time": "2020-01-31T17:20:04.750128",
     "exception": false,
     "start_time": "2020-01-31T17:20:04.468905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff.Boro_Code.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.531253,
     "end_time": "2020-01-31T17:20:05.343899",
     "exception": false,
     "start_time": "2020-01-31T17:20:04.812646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "geosupport_FSET = arcgis.features.FeatureSet.from_dataframe(dff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# geosupport_FSET.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 1.703116,
     "end_time": "2020-01-31T17:20:07.140777",
     "exception": false,
     "start_time": "2020-01-31T17:20:05.437661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(dff) > 0:\n",
    "    tbl_geosupport.delete_features(where=\"objectid > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.374991,
     "end_time": "2020-01-31T17:20:12.593900",
     "exception": false,
     "start_time": "2020-01-31T17:20:07.218909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(dff) >0 :\n",
    "    add_to_geosupport = tbl_geosupport.edit_features(adds = geosupport_FSET.features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 312.985085,
   "end_time": "2020-01-31T17:20:13.453301",
   "environment_variables": {},
   "exception": null,
   "input_path": "weekly2\\final_2_step.ipynb",
   "output_path": "weekly2\\snapshots\\final_2_step\\2020-01-31 12.15.00.343184\\final_2_step.ipynb",
   "parameters": {
    "snapshotDir": "weekly2\\snapshots\\final_2_step\\2020-01-31 12.15.00.343184\\"
   },
   "start_time": "2020-01-31T17:15:00.468216",
   "version": "1.0.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "316px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
